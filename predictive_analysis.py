# -*- coding: utf-8 -*-
"""Predictive-analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-bGPxKjsoqhs1sm-KrIMXQogPTnucPaX

# Proyek Predictive Analysis: Student Performance (Multiple Linear Regression)
- **Nama:** Bizzati Hanif Raushan Fikri
- **Email:** bizzhanif@gmail.com
- **ID Dicoding:** MC006D5Y1740


- Dataset source : https://www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression/data

## **Project Domain: Predicting Student Performance**

Domain projek ini adalah membangun satu **model regresi** tunggal untuk memprediksi *Performance Index* siswa (skor 0–100) berdasarkan berbagai atribut kebiasaan belajar dan demografis, termasuk:

* `study_time` (jam belajar per minggu)
* `previous_scores` (rata-rata skor tes sebelumnya)
* `sleep_hours` (jam tidur rata-rata per malam)
* `sample_papers_practiced` (jumlah soal latihan yang dikerjakan)
* `extracurricular_activities` (partisipasi kegiatan ekstrakurikuler: Yes/No)

Tujuannya adalah:

* Mengidentifikasi siswa yang memerlukan intervensi khusus
* Memahami kontribusi relatif tiap fitur terhadap hasil belajar
* Menyediakan rekomendasi kuantitatif untuk peningkatan performa

---

## **Problem Statements & Goals**

**Problem Statement:**

> 1. Bagaimana memprediksi *Performance Index* siswa baru berdasarkan kombinasi fitur numerik dan kategorikal di atas?
2. Algoritma regresi mana (Linear Regression, Ridge, Lasso) yang memberikan prediksi paling akurat?
3. Fitur apa yang krusial dalam meningkatkan performa siswa?

**Goal:**

>* Membangun satu pipeline regresi yang mencakup pra-pemrosesan (encoding & scaling), pelatihan, dan validasi menggunakan cross-validation.
* Mencapai metrik **MAE ≤ 5.0** pada test set.
* Menginterpretasi koefisien dan signifikansi fitur, termasuk `extracurricular_activities`.

**Solution Statement:**

> Implementasi pipeline scikit-learn yang terdiri dari:
>
> 1. `ColumnTransformer` untuk:
>
>    * `StandardScaler` pada fitur numerik
>    * `OneHotEncoder` (drop-first) pada `extracurricular_activities`
> 2. Menggunakan model regresi terbaik dari ketiga model (Linear Regression / Ridge / Lasso) dituning dengan `GridSearchCV` (5-fold CV).
> 3. Evaluasi performa akhir pada test set (MAE, R²) dan analisis koefisien untuk seleksi model.
> 4. Melakukan analisa feature importance

## Import library
"""

# basic analytical tools; EDA, Visualization, etc.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Data preparation and model training
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import Ridge, Lasso, LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score

"""## Exploratory Data Analysis (EDA)

Load data & cek kebenaran data
"""

df = pd.read_csv("Student_Performance.csv")

# Basic info and summary statistics
print("\nDataFrame Info:")
print(df.info())
df.head()

"""Memvisualisasikan distribusi data masing-masing kelas"""

numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns

for col in numeric_cols:
    plt.figure()
    plt.hist(df[col], bins=20)
    plt.title(f'Histogram of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.tight_layout()
    plt.show()

# Plotting pie chart untuk fitur kategorikal
ex_count = df['Extracurricular Activities'].value_counts()

plt.figure(figsize=(8, 6))
plt.pie(
    ex_count,
    labels=ex_count.index,
    autopct='%1.1f%%',
    startangle=90,
    colors=['#1f77b4', '#ff7f0e'],
    explode= (0.05, 0),
    shadow=True,
    textprops={'fontsize': 10}
)

plt.title('Apakah murid mempunyai aktivitas ekstrakurikuler?', fontsize=12, pad=20)
plt.axis('equal')

plt.show()

"""Membuat dataframe sementara untuk melihat korelasi dengan encoding kelas fitur"""

df_encoded = pd.concat([
    df[numeric_cols],
    pd.get_dummies(df['Extracurricular Activities'], prefix='Extra Activities', drop_first=True)
], axis=1)

corr_all = df_encoded.corr()

"""Membuat heatmap untuk melihat korelasi antar seluruh fitur"""

all_cols = df_encoded.columns

corr = df_encoded.corr()
plt.figure()
plt.imshow(corr, aspect='equal')
plt.colorbar()
plt.title('Heatmap Korelasi seluruh fitur')
plt.xticks(range(len(all_cols)), all_cols, rotation=45, ha='right')
plt.yticks(range(len(all_cols)), all_cols)
plt.tight_layout()
plt.show()

"""**Insight**
- Dari korelasi antar fitur, terlihat bahwa `performance_index` memiliki korelasi cukup erat dengan total jam belajar (`Hours Studied`) dan nilai sebelumnya (`Previous Scores`)

## Data preparation

### Preprocessing

Melakukan pengecekan data kosong, duplikat, dan outlier pada fitur numerik
"""

# Cek missing values pada data
print("Jumlah null pada dataframe:")
print(f"\n{df.isnull().sum()}")

# Cek duplikasi data
print(f"\n\nJumlah duplikat pada Student_Performance.csv: {df.duplicated().sum()}")

# Cek outliers
def detect_outlier_indices(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return series[(series < lower_bound) | (series > upper_bound)].index

numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
outlier_indices = set()
for col in numeric_cols:
    outlier_indices.update(detect_outlier_indices(df[col]))

print(f"Jumlah outlier yang terdeteksi: {len(outlier_indices)}")

#penyimpanan data sebelum preprocessing
df_unprocessed = df.copy()

# Penanganan data null
df.dropna(inplace=True)
print("Jumlah null pada dataframe setelah drop:")
print(f"\n{df.isnull().sum()}")

# Penanganan duplikasi data
df.drop_duplicates(inplace=True)
print(f"\n\nJumlah duplikat pada Student_Performance.csv setelah drop: {df.duplicated().sum()}")

# Penanganan outlier
df.drop(outlier_indices, inplace=True)
print(f"Jumlah outlier yang terdeteksi setelah drop: {len(outlier_indices)}")

df.describe()

"""**Insight:**
- Terdapat beberapa data duplikat yang ditangani dengan drop duplicates
- Tidak terdapat data null
- Tidak terdapat data outlier

### Data splitting & data preparation

split data menjadi dua bagian; data training & data testing
"""

from sklearn.model_selection import train_test_split

X = df.drop('Performance Index', axis=1)
y = df['Performance Index']

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,       # 30% data untuk uji
    random_state=42      # agar hasil konsisten
)

"""Membangun pipeline `preprocessor` untuk scaling fitur numerik serta encoding fitur kategorikal"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline

numeric_feats = ['Hours Studied','Previous Scores','Sleep Hours','Sample Question Papers Practiced']
cat_feats     = ['Extracurricular Activities']

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numeric_feats),
    ('cat', OneHotEncoder(drop='first'), cat_feats)
])

"""## Modeling

### Metrik Evaluasi

Untuk mengukur performa model dalam proyek ini, digunakan dua metrik utama:

#### 1. Mean Absolute Error (MAE)
- MAE menghitung rata-rata kesalahan absolut antara nilai aktual ($y_i$) dan prediksi ($\hat y_i$).
- Metrik ini cocok untuk regresi karena memberikan estimasi seberapa jauh prediksi rata-rata model dari nilai sebenarnya, dalam satuan asli target.
- MAE tidak terlalu sensitif terhadap outlier, sehingga memberikan penilaian yang lebih stabil.

**Formula MAE**:  
$$
{MAE} = \frac{1}{n} \sum_{i=1}^{n} \bigl|y_i - \hat y_i\bigr|
$$

#### 2. Koefisien Determinasi (R²)
- R² menunjukkan proporsi varians target yang berhasil dijelaskan oleh model.
- Nilai R² berkisar antara 0 hingga 1, di mana 1 berarti model menjelaskan semua variasi data, dan 0 berarti tidak ada penjelasan sama sekali.
- Metrik ini membantu menilai seberapa baik model menangkap pola data.

**Formula R²**:  
$$
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat y_i)^2}{\sum_{i=1}^{n} (y_i - \bar y)^2}
$$

### 1. Linear Regression
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score

# Build pipeline
pipe_lr = Pipeline([
    ('pre', preprocessor),
    ('reg', LinearRegression())
])

# Fit
pipe_lr.fit(X_train, y_train)

# Predict & evaluate
y_pred_lr = pipe_lr.predict(X_test)
print("LinearRegression — Test MAE: {:.3f}, R²: {:.3f}".format(
    mean_absolute_error(y_test, y_pred_lr),
    r2_score(y_test, y_pred_lr)
))

# CV estimate
cv_mae_lr = -cross_val_score(pipe_lr, X_train, y_train,
                             cv=5, scoring='neg_mean_absolute_error', n_jobs=-1).mean()
print("LinearRegression — CV MAE (5-fold): {:.3f}".format(cv_mae_lr))

"""### 2. Ridge Regression"""

from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV

# Pipeline + GridSearch for Ridge
pipe_r = Pipeline([
    ('pre', preprocessor),
    ('reg', Ridge(max_iter=5_000))
])

param_grid_r = {'reg__alpha': [0.1, 1, 10, 100]}

grid_r = GridSearchCV(
    pipe_r, param_grid_r,
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1
)
grid_r.fit(X_train, y_train)

best_ridge = grid_r.best_estimator_
print("Ridge    — Best alpha:", grid_r.best_params_['reg__alpha'])
print("Ridge    — CV MAE: {:.3f}".format(-grid_r.best_score_))

# Test evaluation
y_pred_r = best_ridge.predict(X_test)
print("Ridge    — Test MAE: {:.3f}, R²: {:.3f}".format(
    mean_absolute_error(y_test, y_pred_r),
    r2_score(y_test, y_pred_r)
))

"""### 3. Lasso Regression


"""

from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV

# Pipeline + GridSearch for Lasso
pipe_l = Pipeline([
    ('pre', preprocessor),
    ('reg', Lasso(max_iter=10_000))
])

param_grid_l = {'reg__alpha': [0.001, 0.01, 0.1, 1, 10]}

grid_l = GridSearchCV(
    pipe_l, param_grid_l,
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1
)
grid_l.fit(X_train, y_train)

best_lasso = grid_l.best_estimator_
print("Lasso    — Best alpha:", grid_l.best_params_['reg__alpha'])
print("Lasso    — CV MAE: {:.3f}".format(-grid_l.best_score_))

# Test evaluation
y_pred_l = best_lasso.predict(X_test)
print("Lasso    — Test MAE: {:.3f}, R²: {:.3f}".format(
    mean_absolute_error(y_test, y_pred_l),
    r2_score(y_test, y_pred_l)
))

"""## Evaluation

Merangkup hasil evaluasi dari ketiga model yang diuji
"""

import pandas as pd

df_results = pd.DataFrame([
    ['Linear', mean_absolute_error(y_test, y_pred_lr), r2_score(y_test, y_pred_lr)],
    ['Ridge',  mean_absolute_error(y_test, y_pred_r),  r2_score(y_test, y_pred_r)],
    ['Lasso',  mean_absolute_error(y_test, y_pred_l),  r2_score(y_test, y_pred_l)]
], columns=['Model','Test MAE','Test R2']).set_index('Model')

print(df_results)

"""**Insight:**
- Perbandingan antar ketiga model tidak menunjukkan perbedaan yang signifikan, ini menunjukkan ketiga model regresi tersebut setara dalam performa. Namun jika kita ingin lebih teliti model **Ridge** memiliki skor Mean Absolut Error (MAE) yang paling rendah, sehingga model **Ridge** dapat disimpulkan sebagai model yang paling efektif untuk digunakan

Menguji *feature importance* untuk melihat fitur yang paling berkontribusi
"""

import pandas as pd
from sklearn.metrics import mean_absolute_error, r2_score

best_ridge = grid_r.best_estimator_

# Ekstrak model & preprocessor dari pipeline Ridge
model = best_ridge.named_steps['reg']
pre   = best_ridge.named_steps['pre']

# Ambil nama fitur setelah preprocessing
numeric_feats = ['Hours Studied', 'Previous Scores', 'Sleep Hours', 'Sample Question Papers Practiced']
cat_feats     = ['Extracurricular Activities']
onehot        = pre.named_transformers_['cat']
cat_columns   = onehot.get_feature_names_out(cat_feats)
feature_names = numeric_feats + list(cat_columns)

# Ambil koefisien dari Ridge
coefs = model.coef_

# Bangun DataFrame koefisien
coef_df = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': coefs
})

# Hitung kontribusi relatif (%)
coef_df['AbsCoef'] = coef_df['Coefficient'].abs()
total = coef_df['AbsCoef'].sum()
coef_df['Contribution (%)'] = coef_df['AbsCoef'] / total * 100

# Urutkan berdasarkan kontribusi tertinggi
coef_df = coef_df.sort_values('Contribution (%)', ascending=False)

# Cetak hasil dengan format yang mudah dibaca
print("\nRidge Feature Importance (relative contribution):")
for _, row in coef_df.iterrows():
    print(f"- {row.Feature:30s}: {row['Contribution (%)']:5.1f}% (coef = {row.Coefficient:.3f})")

"""**Insight:**
- Pengujian feature importance di atas menunjukkan bahwa nilai sebelumnya (`previous scores`) memiliki dampak terbesar terhadap index performa siswa, begitu pula total jam belajar (`Hours Studied`) dengan koefisien 27.4%

## Conclusion

## Goals

* Membangun satu pipeline regresi yang mencakup pra-pemrosesan (encoding & scaling), pelatihan, dan validasi menggunakan cross-validation. ✅
* Mencapai metrik **MAE ≤ 5.0** pada test set. ✅
* Menginterpretasi koefisien dan signifikansi fitur ✅

---

## Results

Berdasarkan **evaluasi test set**:

| Model             | Test MAE | Test R² |
| ----------------- | -------- | ------- |
| Linear Regression | 1.646    | 0.988   |
| Ridge Regression  | 1.646    | 0.988   |
| Lasso Regression  | 1.646    | 0.988   |

- Semua model memberikan performa yang sangat mirip, dengan **MAE ≈ 1.65** dan **R² ≈ 0.988**.
- **Linear Regression** sudah mampu menangkap pola linier data dengan sangat baik tanpa regularisasi tambahan.
- **Ridge Regression** pilihan terbaik secara teknis, karena memberikan perfoma paling stabil, meskipun sangat tipis lebih baik daripada Linear.
- **Lasso Regression** bisa menyederhanakan model dengan meng-nol-kan fitur, tapi tidak terjadi dalam kasus ini (karena semua fitur cukup relevan).

**Analisis Koefisien (Ridge Regression):**

| Feature                          | Contribution (%) | Coefficient |
| -------------------------------- | ---------------- | ----------- |
| Previous Scores                  | 65.5%            | 17.620      |
| Hours Studied                    | 27.4%            | 7.373       |
| Sleep Hours                      | 3.0%             | 0.802       |
| Extracurricular Activities (Yes) | 2.1%             | 0.574       |
| Sample Question Papers Practiced | 2.0%             | 0.540       |

* **Prediksi kuat** didorong oleh `Previous Scores` dan `Hours Studied` (total >87% kontribusi).
* Fitur lain memberikan kontribusi positif kecil, termasuk `extracurricular_activities`.

---

## Solusi setelah analisis

1. **Prediksi Performance Index**: Model **Ridge Regression** memenuhi target MAE ≤ 5.0 dengan skor terendah MAE ≈ 1.65 dan R² ≈ 0.988.
2. **Algoritma Terbaik**: Ketiga algoritma (Linear, Ridge, Lasso) memiliki performa setara, sehingga Linear Regression dipilih karena kesederhanaan dan interpretabilitas.
3. **Rekomendasi**: Berdasarkan koefisien, peningkatan **Previous Scores** dan **Hours Studied** adalah strategi paling efektif untuk menaikkan skor siswa.

Model ini siap digunakan sebagai alat bantu keputusan untuk intervensi akademik di lembaga pendidikan.
"""